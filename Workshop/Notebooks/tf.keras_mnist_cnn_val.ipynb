{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf.keras_mnist_cnn_val.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"axEae3e_36rd","colab_type":"text"},"source":["#Step 0 - Import the various code libraries\n","\n","To begin, we import some library modules and functions that we will use.   \n","\n","Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation - see https://keras.io/.\n","Numpy is a collection of math functions including various matrix operations - see http://www.numpy.org/.   \n","Matplotlib is a 2D plotting library  - see https://matplotlib.org/.\n"]},{"cell_type":"code","metadata":{"id":"rVtRsr_4o8E9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"outputId":"1ed748a6-beb1-44fe-8bbd-76cd5fabf9fe","executionInfo":{"status":"ok","timestamp":1565288720560,"user_tz":180,"elapsed":1613,"user":{"displayName":"Andy McIntyre","photoUrl":"https://lh4.googleusercontent.com/-y37TF4cy-Gk/AAAAAAAAAAI/AAAAAAAABEw/1GQlfr4rmGU/s64/photo.jpg","userId":"02194312830009157676"}}},"source":["'''\n","keras_mnist_cnn_val.py\n","\n","Trains a convolution neural network on the MNIST dataset.\n","Gets to 99.25% test accuracy after 12 epochs when using 60,000 train examples\n","(and still a lot of margin for parameter tuning).\n","Slow on a CPU, but only 16 seconds per epoch on a GRID K520 GPU.\n","'''\n","\n","from __future__ import print_function\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras.datasets import mnist\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Set the seed value of the random number generator\n","random_seed = 2\n","np.random.seed(random_seed)\n","\n","print(tf.VERSION)\n","print(tf.keras.__version__)\n","\n","print(\"The enviriment is ready.\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["1.14.0\n","2.2.4-tf\n","The enviriment is ready.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4Hhnx_kW4zco","colab_type":"text"},"source":["#Step 1 - Set the learning parameters and load the data.\n","The data is loaded into three data sets: training, validation and testing.\n","The validation (or tuning) set is used to ensure the model does not overfit to the training data."]},{"cell_type":"code","metadata":{"id":"rJDYrktD4box","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":151},"outputId":"c63ba59d-9344-4acf-cfb0-d5a4f073dc69","executionInfo":{"status":"ok","timestamp":1565288721259,"user_tz":180,"elapsed":2301,"user":{"displayName":"Andy McIntyre","photoUrl":"https://lh4.googleusercontent.com/-y37TF4cy-Gk/AAAAAAAAAAI/AAAAAAAABEw/1GQlfr4rmGU/s64/photo.jpg","userId":"02194312830009157676"}}},"source":["batch_size = 128\n","num_classes = 10\n","epochs = 12\n","train_ex = 2000\n","\n","''' Load the data in, choose the number of training, val, test\n","    examples we want, and reshape the x data to the\n","    correct shape (28x28x1). '''\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","x_train = x_train.reshape(60000, 28, 28, 1)\n","x_tune = x_train[50000:60000]\n","x_train = x_train[0:train_ex]\n","x_test = x_test.reshape(10000, 28, 28, 1)\n","x_train = x_train.astype('float32')\n","x_tune = x_tune.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_tune /= 255\n","x_test /= 255\n","\n","# convert class vectors to binary class matrices\n","y_tune  = tf.keras.utils.to_categorical(y_train[50000:60000], num_classes)\n","y_train = tf.keras.utils.to_categorical(y_train[0:train_ex], num_classes)\n","y_test  = tf.keras.utils.to_categorical(y_test, num_classes)\n","\n","print(x_train.shape, 'train samples')\n","print(x_tune.shape, 'tune samples')\n","print(x_test.shape, 'test samples')\n","print(y_train.shape, 'train targets')\n","print(y_tune.shape, 'tune targets')\n","print(y_test.shape, 'test targets')\n","\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","(2000, 28, 28, 1) train samples\n","(10000, 28, 28, 1) tune samples\n","(10000, 28, 28, 1) test samples\n","(2000, 10) train targets\n","(10000, 10) tune targets\n","(10000, 10) test targets\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kcm-54Q35El3","colab_type":"text"},"source":["#Step 2 - Configure the neural network architecture (graph) \n","Keras follows the layers principle, where each network layer\n","is independent and can be stacked and merged together.\n","The Sequential model assumes that there is one long\n","stack, with no branching.\n","\n","Typically, you will place a convolution layer, followed by maxpooling layer, followed by a dropout layer.  Combined these are sometimes referred to as convolutin stages."]},{"cell_type":"code","metadata":{"id":"HLnzHHhQ46dl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":487},"outputId":"a23b3eda-cf1f-4f94-8e47-dcc6391ea33b","executionInfo":{"status":"ok","timestamp":1565288997147,"user_tz":180,"elapsed":482,"user":{"displayName":"Andy McIntyre","photoUrl":"https://lh4.googleusercontent.com/-y37TF4cy-Gk/AAAAAAAAAAI/AAAAAAAABEw/1GQlfr4rmGU/s64/photo.jpg","userId":"02194312830009157676"}}},"source":["model = tf.keras.Sequential()\n","\n","\"\"\"\n","filters gives us the number of filters in the layer,the\n","more filters we have, the more information we can learn\n","\n","kernel_size is the size of the convolution filter\n","\n","activation is the activation function on each node,\n","we use relu, could also use sigmoid\n","\n","input_shape is the shape of the image. We reshaped\n","the data above to get it in the right shape. The 1\n","represents a grayscale image. If you had a colour\n","image (RGB), the last dimension would be 3.\n","\"\"\"\n","model.add(layers.Conv2D(filters=32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=(28, 28, 1)))\n","\n","\"\"\" MaxPooling takes an NxM rectangle and find the maxiumum\n","value in that square, and discards the rest. Since we are\n","doing 2x2 pooling, it has the effect of halving the height\n","and width of the image. \"\"\"\n","model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n","\n","# Set a random 25% of nodes to 0 to prevent overfitting\n","model.add(layers.Dropout(0.25))\n","\n","\"\"\" Add a second conv layer \n","Note we don't need to give the shape between the first and\n","second layer, Keras figures that out for us. \"\"\"\n","model.add(layers.Conv2D(32, (2, 2), activation='relu'))\n","model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n","model.add(layers.Dropout(0.25))\n","\n","# Transform the 6x6x32 values to a flat 1152\n","model.add(layers.Flatten())\n","\n","# Add an additonal hidden layer of dense nodes\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","\n","# Finish with 10 softmax output nodes\n","model.add(layers.Dense(num_classes, activation='softmax'))\n","\n","model.summary()   # Show a summary of the network architecture\n","\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 12, 12, 32)        4128      \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 6, 6, 32)          0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 6, 6, 32)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 1152)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 128)               147584    \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 153,322\n","Trainable params: 153,322\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p8A0nKQv6UGc","colab_type":"text"},"source":["#Step 3 - Compile the model and fit the data to it\n","The code for compiling two learning algorithms are provided to demostrate the variety of approaches that can be used to train networks.   \n","The first uses the Adadelta Gradient Descent algorithm and does not use a validation set to prevent overfitting. \n","The second uses the Stochastic Gradient Descent algorithm with momentum and a validation set to prevent overfitting.\n","Both methods use the categorical cross-entropy loss function, which works well with the softmax activation output nodes. \n","Using comments you can select the algorithm you wish to compile. \n","\n"]},{"cell_type":"code","metadata":{"id":"aP7PGIeW6SEU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":202},"outputId":"6bf76c9f-f979-40e8-d278-ed9b0da74e7e","executionInfo":{"status":"ok","timestamp":1565289751728,"user_tz":180,"elapsed":3148,"user":{"displayName":"Andy McIntyre","photoUrl":"https://lh4.googleusercontent.com/-y37TF4cy-Gk/AAAAAAAAAAI/AAAAAAAABEw/1GQlfr4rmGU/s64/photo.jpg","userId":"02194312830009157676"}}},"source":["'''\n","#############\n","# Adadelta Gradient Descent without use of validation set \n","# to prevent overfitting\n","\n","\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0),\n","              metrics=['accuracy'])\n","\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))\n","#\n","#############\n","'''\n","\n","#############\n","# Stochastic Gradient Descent with momentum and a validation set \n","# to prevent overfitting\n","\n","sgd = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)\n","\n","model.compile(loss=tf.keras.losses.categorical_crossentropy,\n","#              optimizer=sgd,\n","              optimizer=tf.keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0),\n","              metrics=['accuracy'])\n","\n","# Configure early stopping using validation accuracy from tune partition  \n","es = tf.keras.callbacks.EarlyStopping(monitor='val_acc',\n","                   patience=2,  # epochs to wait after min loss\n","                   verbose=1, \n","                   restore_best_weights=True) # restore the best weights\n","\n","# The history structure keeps tabs on what happened during the session\n","history = model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_tune, y_tune),\n","          callbacks=[es])\n","#\n","#############\n","\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Train on 2000 samples, validate on 10000 samples\n","Epoch 1/12\n","2000/2000 [==============================] - 1s 301us/sample - loss: 0.1511 - acc: 0.9510 - val_loss: 0.1464 - val_acc: 0.9570\n","Epoch 2/12\n","2000/2000 [==============================] - 0s 160us/sample - loss: 0.1485 - acc: 0.9475 - val_loss: 0.1337 - val_acc: 0.9605\n","Epoch 3/12\n","2000/2000 [==============================] - 0s 161us/sample - loss: 0.1374 - acc: 0.9565 - val_loss: 0.1323 - val_acc: 0.9597\n","Epoch 4/12\n","1280/2000 [==================>...........] - ETA: 0s - loss: 0.1362 - acc: 0.9539Restoring model weights from the end of the best epoch.\n","2000/2000 [==============================] - 0s 163us/sample - loss: 0.1292 - acc: 0.9565 - val_loss: 0.1522 - val_acc: 0.9562\n","Epoch 00004: early stopping\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M6_xZcGj7hhK","colab_type":"text"},"source":["#Step 4 - Evaluate the model on the test set and print the results.\n","Pass the independent test data through the trained model and compute the test set cross-entropy  and test classification accuracy.\n","For the first ten examples in the test set show us the examples and the associated network predictions.\n","\n"]},{"cell_type":"code","metadata":{"id":"QnrQvnpf7gcm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":114},"outputId":"3b5add89-e7b2-477b-8e99-92fe9cefe649","executionInfo":{"status":"ok","timestamp":1565289759208,"user_tz":180,"elapsed":2698,"user":{"displayName":"Andy McIntyre","photoUrl":"https://lh4.googleusercontent.com/-y37TF4cy-Gk/AAAAAAAAAAI/AAAAAAAABEw/1GQlfr4rmGU/s64/photo.jpg","userId":"02194312830009157676"}}},"source":["score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])\n","\n","predictions = model.predict(x_test, verbose=0)\n","for i in range(10):\n","    subplt = plt.subplot(int(i / 10) + 1, 10, i + 1)\n","    # no sense in showing labels if they don't match the letter\n","    hot_index = np.argmax(predictions[i])\n","    subplt.set_title('P:{0}'.format(hot_index))\n","    subplt.axis('off')\n","    letter = x_test[i]\n","    subplt.matshow(np.reshape(letter, [28, 28]))\n","    plt.draw()\n","    \n","plt.show()"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Test loss: 0.13144171508550645\n","Test accuracy: 0.96\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAA/CAYAAADwizNIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQlFG+D9SClYLAW+QpQAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 10 Axes>"]},"metadata":{"tags":[]}}]}]}