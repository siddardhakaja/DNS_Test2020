{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf.keras_mnist_sigmoid_val.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["5GIwOKhXkXzm","JL9-f1Uan9Zp","VxcvVz76o0c1","LpbMgHV_nukD","TentRGqRZe6y"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5GIwOKhXkXzm","colab_type":"text"},"source":["#Step 0 - Import the various code libraries\n","\n","To begin, we import some library modules and functions that we will use.   \n","\n","Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation - see https://keras.io/.\n","Numpy is a collection of math functions including various matrix operations - see http://www.numpy.org/.   \n","Matplotlib is a 2D plotting library  - see https://matplotlib.org/.\n"]},{"cell_type":"code","metadata":{"id":"enU70fh-ybeB","colab_type":"code","colab":{}},"source":["'''\n","keras_mnist_sigmoid_val.py\n","\n","Trains a simple deep NN on the MNIST dataset.\n","Uses a simple sigmoid activation fucntion and MSE loss. \n","Uses a separate validation/tuning set to determine best model.\n","Gets to 98.40% test accuracy after 20 epochs\n","(there is *a lot* of margin for parameter tuning).\n","2 seconds per epoch on a K520 GPU.\n","'''\n","\n","from __future__ import print_function\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras.datasets import mnist\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Set the seed value of the random number generator\n","random_seed = 2\n","np.random.seed(random_seed)\n","\n","print(tf.VERSION)\n","print(tf.keras.__version__)\n","\n","print(\"The enviriment is ready.\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JL9-f1Uan9Zp","colab_type":"text"},"source":["#Step 1 - Set the learning parameters and load the data.\n","The data is loaded into three data sets: training, validation and testing.\n","The validation (or tuning) set is used to ensure the model does not overfit to the training data."]},{"cell_type":"code","metadata":{"id":"L9VaB5Tck_IN","colab_type":"code","colab":{}},"source":["batch_size = 128\n","num_classes = 10\n","epochs = 3\n","\n","# the data, split between train and test sets\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","x_train = x_train.reshape(60000, 784)\n","x_tune = x_train[50000:60000]\n","x_train = x_train[0:50000]\n","x_test = x_test.reshape(10000, 784)\n","x_train = x_train.astype('float32')\n","x_tune = x_tune.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_tune /= 255\n","x_test /= 255\n","print(x_train.shape[0], 'train samples')\n","print(x_tune.shape[0], 'tune samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_tune  = tf.keras.utils.to_categorical(y_train[50000:60000], num_classes)\n","y_train = tf.keras.utils.to_categorical(y_train[0:50000], num_classes)\n","y_test  = tf.keras.utils.to_categorical(y_test, num_classes)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VxcvVz76o0c1","colab_type":"text"},"source":["#Step 2 - Configure the neural network architecture (graph) \n","By default the network is similar to the simple back-prop algorithm. \n","It has one hidden layer of 512 nodes with sigmoid activation functions.\n","And it has an output layer of 10 nodes each with a  sigmoid activation function.\n","\n","We shall see, that this can be changed in several ways to make the network more effective in developing an accuracte model."]},{"cell_type":"code","metadata":{"id":"SzAr2Pmeo5UW","colab_type":"code","colab":{}},"source":["model = tf.keras.Sequential()\n","model.add(layers.Dense(512, activation='sigmoid', input_shape=(784,)))\n","#model.add(layers.Dense(num_classes, activation='sigmoid'))\n","model.add(layers.Dense(num_classes, activation='softmax'))\n","\n","model.summary()    # Produce a summary of the network architecture\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LpbMgHV_nukD","colab_type":"text"},"source":["#Step 3 - Compile the model and fit the data to it\n","The model uses the mean squared error (MSE) loss function, which works well with the sigmoid activation output nodes, and the stochastic gradient descent (SGD) weight update algorithm.\n","The validation set is used to monitor the model to see if it overfits to the training data."]},{"cell_type":"code","metadata":{"id":"b8axHZLCpfXO","colab_type":"code","colab":{}},"source":["#model.compile(loss='mean_squared_error',\n","model.compile(loss=tf.keras.losses.categorical_crossentropy,\n","              optimizer=tf.keras.optimizers.SGD(lr=0.1, momentum=0.9),\n","#              optimizer=RMSprop(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_tune, y_tune))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TentRGqRZe6y","colab_type":"text"},"source":["#Step 4 - Evaluate the model on the test set and print the results.\n","Pass the independent test data through the trained model and compute the test MSE  and test classification accuracy.\n","For the first ten examples in the test set show us the examples and the associated network predictions."]},{"cell_type":"code","metadata":{"id":"510sytSJZbxK","colab_type":"code","colab":{}},"source":["score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])\n","\n","predictions = model.predict(x_test, verbose=0)\n","for i in range(10):\n","    subplt = plt.subplot(int(i / 10) + 1, 10, i + 1)\n","    # no sense in showing labels if they don't match the letter\n","    hot_index = np.argmax(predictions[i])\n","    subplt.set_title('P:{0}'.format(hot_index))\n","    subplt.axis('off')\n","    letter = x_test[i]\n","    subplt.matshow(np.reshape(letter, [28, 28]))\n","    plt.draw()\n","    \n","plt.show()"],"execution_count":0,"outputs":[]}]}